{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyedflib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"chb01_01.edf\"\n",
    "f = pyedflib.EdfReader(file_name)\n",
    "n = f.signals_in_file\n",
    "signal_labels = f.getSignalLabels() \n",
    "sigbufs = np.zeros((n, f.getNSamples()[0]))\n",
    "for i in np.arange(n):\n",
    "        sigbufs[i, :] = f.readSignal(i)\n",
    "# section each data in sigbufs into 20 seconds\n",
    "# for signal in sigbufs:\n",
    "#         for i in range(0, len(signal), 2000):\n",
    "#                 print(signal[i:i+4000])\n",
    "#                 plt.plot(signal[i:i+4000])\n",
    "#                 plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_name):\n",
    "    f = pyedflib.EdfReader(file_name)\n",
    "    n = f.signals_in_file\n",
    "    signal_labels = f.getSignalLabels() \n",
    "    sigbufs = np.zeros((n, f.getNSamples()[0]))\n",
    "    for i in np.arange(n):\n",
    "            sigbufs[i, :] = f.readSignal(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_signals_in_20_seconds(sigbufs):\n",
    "    #section each data in sigbufs into 20 seconds data and return the list of 20 seconds data\n",
    "    signals_in_20_seconds = []\n",
    "    for signal in sigbufs:\n",
    "        for i in range(0, len(signal), 20000):\n",
    "            signals_in_20_seconds.append(signal[i:i+20000])\n",
    "    return signals_in_20_seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sigbufs = partition_signals_in_20_seconds(sigbufs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1081"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_sigbufs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a convolution neural network with tensorflow class \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "class CNN:\n",
    "    def __init__(self, learning_rate=0.001, num_classes=2, batch_size=50, dropout=0.75, num_epochs=10, evaluate_every=100, checkpoint_every=100, allow_soft_placement=True, log_device_placement=False):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.dropout = dropout\n",
    "        self.num_epochs = num_epochs\n",
    "        self.evaluate_every = evaluate_every\n",
    "        self.checkpoint_every = checkpoint_every\n",
    "        self.allow_soft_placement = allow_soft_placement\n",
    "        self.log_device_placement = log_device_placement\n",
    "\n",
    "    def train(self, train_data, train_labels, test_data, test_labels):\n",
    "        # create a graph to hold the model\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            self.session_conf = tf.ConfigProto(allow_soft_placement=self.allow_soft_placement, log_device_placement=self.log_device_placement)\n",
    "            self.sess = tf.Session(config=self.session_conf)\n",
    "            with self.sess.as_default():\n",
    "                # create the model\n",
    "                self.cnn()\n",
    "                # define training procedure\n",
    "                self.global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "                self.optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "                self.grads_and_vars = self.optimizer.compute_gradients(self.loss)\n",
    "                self.train_op = self.optimizer.apply_gradients(self.grads_and_vars, global_step=self.global_step)\n",
    "                # keep track of gradient values and sparsity\n",
    "                self.grad_summaries = []\n",
    "                for g, v in self.grads_and_vars:\n",
    "                    if g is not None:\n",
    "                        self.grad_hist_summary = tf.summary.histogram(\"{}/grad/hist\".format(v.name), g)\n",
    "                        self.sparsity_summary = tf.summary.scalar(\"{}/grad/sparsity\".format(v.name), tf.nn.zero_fraction(g))\n",
    "                        self.grad_summaries.append(self.grad_hist_summary)\n",
    "                        self.grad_summaries.append(self.sparsity_summary)\n",
    "                self.grad_summaries_merged = tf.summary.merge(self.grad_summaries)\n",
    "                # output directory for models and summaries\n",
    "                self.timestamp = str(int(time.time()))\n",
    "                self.out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", self.timestamp))\n",
    "                print(\"Writing to {}\\n\".format(self.out_dir))\n",
    "                # summaries for loss and accuracy\n",
    "                self.loss_summary = tf.summary.scalar(\"loss\", self.loss)\n",
    "                self.acc_summary = tf.summary.scalar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a convolution neural network class with pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
